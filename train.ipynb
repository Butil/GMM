{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn import mixture as mix\n",
    "from sklearn.externals import joblib\n",
    "import fnmatch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(img, crop_size):\n",
    "    s = img.shape\n",
    "    v = s[0]//2 - crop_size//2\n",
    "    h = s[1]//2 - crop_size//2\n",
    "    cropped_img = img[v:v + crop_size, h: h + crop_size]\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_patches(patches, shuffle=True):\n",
    "    if shuffle:\n",
    "        np.random.shuffle(patches)\n",
    "    patches = np.float32(patches)\n",
    "    # need to do this patch by patch, otherwise memory consuming\n",
    "    for row in xrange(patches.shape[0]):\n",
    "        patch = patches[row,:]\n",
    "        norm_patch = patch - np.mean(patch)\n",
    "        norm_patch = norm_patch - np.min(norm_patch)\n",
    "        norm_patch /= np.max(norm_patch)\n",
    "        patches[row,:]=norm_patch\n",
    "    patches[np.isnan(patches)] = 0\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_patches(processed_set, Check_dir, image_size, patches_per_image, b, seed=None):\n",
    "    imagenames = os.listdir(processed_set)\n",
    "    total_num_of_patches = patches_per_image * len(imagenames)\n",
    "    patches = np.empty((total_num_of_patches, b * b), np.uint8)\n",
    "    np.random.seed(seed)\n",
    "    j = 0\n",
    "    for name in imagenames:\n",
    "        img = cv2.imread(processed_set + name,  0)\n",
    "        if any(dim != image_size for dim in img.shape):\n",
    "            img = crop_center(img, image_size)\n",
    "        for i in xrange(patches_per_image):\n",
    "            m = np.random.randint(0, image_size - b + 1)\n",
    "            n = np.random.randint(0, image_size - b + 1)      \n",
    "            patches[j] = np.reshape(img[m:m + b, n:n + b], (1, b*b))\n",
    "            j += 1\n",
    "    patches = normalize_patches(patches)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_GMM(n_components, processed_set, Check_dir, image_size, patches_per_image, b):\n",
    "    if not os.path.exists(Check_dir):\n",
    "        os.makedirs(Check_dir)\n",
    "    processing = processed_set[11:-5]\n",
    "    checkpoints = fnmatch.filter(os.listdir(Check_dir), '*GMM_' + processing + '_*.pkl')\n",
    "    \n",
    "    if len(checkpoints) != 0:\n",
    "        last_checkpoint = checkpoints[-1]\n",
    "        re_ckpt_number = re.search(processing + '_(.*).pkl', last_checkpoint)\n",
    "        if re_ckpt_number.group(1) == 'final':\n",
    "            return None, None, None\n",
    "        GMM = joblib.load(Check_dir + last_checkpoint)\n",
    "        initial_i = int(re_ckpt_number.group(1))\n",
    "        patches = joblib.load(Check_dir + 'Patches_' + processing + '.pkl')\n",
    "    else:\n",
    "        initial_i = 0\n",
    "        GMM = mix.GaussianMixture(n_components=n_components, warm_start=True)\n",
    "        \n",
    "    patches_path = Check_dir + 'Patches_' + processing + '.pkl'\n",
    "    if os.path.isfile(patches_path):\n",
    "        patches = joblib.load(patches_path)\n",
    "    else:\n",
    "        patches = generate_patches(processed_set, Check_dir, image_size, patches_per_image, b)\n",
    "        joblib.dump(patches, patches_path)\n",
    "        \n",
    "    return GMM, initial_i, patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(processed_set, n_components = 200, b = 8, \\\n",
    "          patches_per_image = 500, image_size = 512, \\\n",
    "          batch_size = 10000, save_interval = 20):\n",
    "    Check_dir = '../Models/' + str(image_size) + '/'\n",
    "    GMM, initial_i, patches = initialize_GMM(n_components, processed_set, \\\n",
    "                                             Check_dir, image_size, patches_per_image, b)  \n",
    "    if GMM is None:\n",
    "        # already trained\n",
    "        return 0\n",
    "    total_num_of_patches = patches.shape[0]\n",
    "    processing = processed_set[11:-5]\n",
    "    for i in range(initial_i, total_num_of_patches / batch_size):\n",
    "        GMM.fit(patches[i * batch_size: (i+1) * batch_size])\n",
    "        if i % save_interval == 0:\n",
    "            joblib.dump(GMM, Check_dir + 'GMM_' + processing + '_' + str((i+1) * batch_size) + '.pkl')\n",
    "    GMM.fit(patches[-(total_num_of_patches % batch_size):])\n",
    "    joblib.dump(GMM, Check_dir + 'GMM_' + processing + '_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Processings_TRN = ['ORI', 'GF', 'JPG', 'MF', 'RS', 'USM', 'WGN']\n",
    "Processings_TRN = ['../DataSet/' + proc + '/TRN/' for proc in Processings_TRN]\n",
    "image_sizes = [16, 32, 512]\n",
    "for image_size in image_sizes:\n",
    "    for processed_set in Processings_TRN:\n",
    "        train(processed_set, image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
