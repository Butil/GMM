{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn import mixture as mix\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(processed_set, n_components = 200, b = 8, \\\n",
    "          patches_per_image = 500, batch_size = 10000, \\\n",
    "          save_interval = 20, seed=None):\n",
    "    imagenames = os.listdir(processed_set)\n",
    "    total_num_of_patches = patches_per_image * len(imagenames)\n",
    "    patches = np.empty((total_num_of_patches, b * b), np.uint8)\n",
    "    np.random.seed(seed)\n",
    "    j = 0\n",
    "    for name in imagenames:\n",
    "        img = cv2.imread(processed_set + name,  0)\n",
    "        s = img.shape\n",
    "        patch_idx = -np.ones((patches_per_image, 2), np.uint8)\n",
    "        for i in xrange(patches_per_image):\n",
    "            while True:\n",
    "                # don't use same patch twice\n",
    "                m = np.random.randint(0, s[0] - b + 1)\n",
    "                n = np.random.randint(0, s[1] - b + 1)\n",
    "                if [m, n] not in patch_idx:\n",
    "                    patch_idx[i] = [m, n]\n",
    "                    break        \n",
    "            patches[j] = np.reshape(img[m:m + b, n:n + b], (1, b*b))\n",
    "            j += 1\n",
    "    np.random.shuffle(patches)\n",
    "    GMM = mix.GaussianMixture(n_components=n_components, warm_start=True)\n",
    "    Check_dir = '../Models/'\n",
    "    if not os.path.exists(Check_dir):\n",
    "        os.makedirs(Check_dir)\n",
    "    processing = processed_set[11:-5]\n",
    "    for i in range(total_num_of_patches / batch_size):\n",
    "        GMM.fit(patches[i * batch_size: (i+1) * batch_size])\n",
    "        if i % 20 == 0:\n",
    "            joblib.dump(GMM, Check_dir + 'GMM_' + processing + '_' + str((i+1) * batch_size) + '.pkl')\n",
    "    GMM.fit(patches[-(total_num_of_patches % batch_size):])\n",
    "    joblib.dump(GMM, Check_dir + 'GMM_' + processing + '_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\mixture\\base.py:237: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  % (init + 1), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "Processings_TRN = ['ORI', 'GF', 'JPG', 'MF', 'RS', 'USM', 'WGN']\n",
    "Processings_TRN = ['../DataSet/' + proc + '/TRN/' for proc in Processings_TRN]\n",
    "for processed_set in Processings_TRN:\n",
    "    train(processed_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
